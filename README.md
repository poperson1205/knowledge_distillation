# Knowledge Distillation

This repository is for testing knowledge distillation. Especially for experiments on MNIST, which is described in this paper: Hinton et. al. "Distilling the Knowledge in a Neural Network". NIPS2014.

![](learning_curve.png)